{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation Engines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import packages and data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Spark configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F  \n",
    "\n",
    "from pyspark import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "\n",
    "from pyspark.sql.functions import min, max, avg,col\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS, ALSModel\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.feature import HashingTF, MinHashLSH\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.2\n"
     ]
    }
   ],
   "source": [
    "# Import the PySpark module\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create SparkSession object\n",
    "spark = SparkSession.builder \\\n",
    "                    .master('local[*]') \\\n",
    "                    .appName('recommender') \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "\n",
    "# Print out Spark version\n",
    "print(spark.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create checkpoint\n",
    "sc = SparkContext.getOrCreate(SparkConf())\n",
    "sc.setCheckpointDir('checkpoint/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: recommender\n",
      "Driver TCP port: 54271\n",
      "Number of partitions: 200\n"
     ]
    }
   ],
   "source": [
    "# Name of the Spark application instance\n",
    "app_name = spark.conf.get('spark.app.name')\n",
    "print(\"Name: %s\" % app_name)\n",
    "\n",
    "# Driver TCP port\n",
    "driver_tcp_port = spark.conf.get('spark.driver.port')\n",
    "print(\"Driver TCP port: %s\" % driver_tcp_port)\n",
    "\n",
    "# Number of join partitions\n",
    "num_partitions = spark.conf.get('spark.sql.shuffle.partitions')\n",
    "print(\"Number of partitions: %s\" % num_partitions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data contain 100836 records.\n"
     ]
    }
   ],
   "source": [
    "# Read data from CSV file\n",
    "ratings = spark.read.csv('ratings.csv',\n",
    "                         sep=',',\n",
    "                         header=True,\n",
    "                         inferSchema=True,\n",
    "                         nullValue='NA')\n",
    "# Get number of records\n",
    "print(\"The data contain %d records.\" % ratings.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|      1|   4.0|964982703|\n",
      "|     1|      3|   4.0|964981247|\n",
      "|     1|      6|   4.0|964982224|\n",
      "|     1|     47|   5.0|964983815|\n",
      "|     1|     50|   5.0|964982931|\n",
      "+------+-------+------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data contain 9742 records.\n"
     ]
    }
   ],
   "source": [
    "# Read data from CSV file\n",
    "movies = spark.read.csv('movies.csv',\n",
    "                         sep=',',\n",
    "                         header=True,\n",
    "                         inferSchema=True,\n",
    "                         nullValue='NA')\n",
    "# Get number of records\n",
    "print(\"The data contain %d records.\" % movies.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|              genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
      "|      5|Father of the Bri...|              Comedy|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Content-based recommendation engine\n",
    "       The main approach is to calculate Jaccard similarity amongs movies based on their genres. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split genres on the | character \n",
    "genres_split = F.split(movies['genres'], '\\|')\n",
    "movies_genres_split = movies.withColumn('genre_split', genres_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|movieId|         genre_split|\n",
      "+-------+--------------------+\n",
      "|      1|[Adventure, Anima...|\n",
      "|      2|[Adventure, Child...|\n",
      "|      3|   [Comedy, Romance]|\n",
      "|      4|[Comedy, Drama, R...|\n",
      "|      5|            [Comedy]|\n",
      "+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create df with movieId and genre_split \n",
    "id_genres = movies_genres_split.select('movieId','genre_split')\n",
    "id_genres.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply  HashingTF and MinHashLSH function to return the right format to feed to algorithm\n",
    "classifier = Pipeline(stages=[\n",
    "                              HashingTF(inputCol=\"genre_split\", outputCol=\"vectors\"),\n",
    "                              MinHashLSH(inputCol=\"vectors\", outputCol=\"lsh\")\n",
    "                             ]).fit(id_genres)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Calculate Jaccard similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o38928.save.\n: java.io.IOException: Path content_based_filter already exists. To overwrite it, please use write.overwrite().save(path) for Scala and use write().overwrite().save(path) for Java and Python.\n\tat org.apache.spark.ml.util.FileSystemOverwrite.handleOverwrite(ReadWrite.scala:683)\n\tat org.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:167)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.super$save(Pipeline.scala:344)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$4(Pipeline.scala:344)\n\tat org.apache.spark.ml.MLEvents.withSaveInstanceEvent(events.scala:176)\n\tat org.apache.spark.ml.MLEvents.withSaveInstanceEvent$(events.scala:171)\n\tat org.apache.spark.ml.util.Instrumentation.withSaveInstanceEvent(Instrumentation.scala:42)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$3(Pipeline.scala:344)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$3$adapted(Pipeline.scala:344)\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.save(Pipeline.scala:344)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-b2b90f82b704>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Save fitted model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"content_based_filter\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load back to use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclassifier_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipelineModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"content_based_filter\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/c/lib/python3.8/site-packages/pyspark/ml/util.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"path should be a basestring, got type %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/c/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/c/lib/python3.8/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/c/lib/python3.8/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o38928.save.\n: java.io.IOException: Path content_based_filter already exists. To overwrite it, please use write.overwrite().save(path) for Scala and use write().overwrite().save(path) for Java and Python.\n\tat org.apache.spark.ml.util.FileSystemOverwrite.handleOverwrite(ReadWrite.scala:683)\n\tat org.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:167)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.super$save(Pipeline.scala:344)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$4(Pipeline.scala:344)\n\tat org.apache.spark.ml.MLEvents.withSaveInstanceEvent(events.scala:176)\n\tat org.apache.spark.ml.MLEvents.withSaveInstanceEvent$(events.scala:171)\n\tat org.apache.spark.ml.util.Instrumentation.withSaveInstanceEvent(Instrumentation.scala:42)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$3(Pipeline.scala:344)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$3$adapted(Pipeline.scala:344)\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.save(Pipeline.scala:344)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "# Save fitted model\n",
    "classifier.write().save(\"content_based_filter\")\n",
    "\n",
    "# Load back to use\n",
    "classifier_ = PipelineModel.load(\"content_based_filter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+----------------+\n",
      "|movieId|         genre_split|             vectors|             lsh|\n",
      "+-------+--------------------+--------------------+----------------+\n",
      "|      1|[Adventure, Anima...|(262144,[4915,139...|[[5.87112014E8]]|\n",
      "|      2|[Adventure, Child...|(262144,[13956,42...|[[5.87112014E8]]|\n",
      "|      3|   [Comedy, Romance]|(262144,[4915,160...|[[9.15231855E8]]|\n",
      "|      4|[Comedy, Drama, R...|(262144,[4915,160...|[[9.15231855E8]]|\n",
      "|      5|            [Comedy]|(262144,[4915],[1...|[[9.15231855E8]]|\n",
      "+-------+--------------------+--------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transform id_genres\n",
    "id_genres_hashed = classifier.transform(id_genres)\n",
    "id_genres_hashed.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate Jaccard similarity amongs movies\n",
    "\n",
    "genres_matches = classifier.stages[-1].approxSimilarityJoin(id_genres_hashed, id_genres_hashed, 0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------------+\n",
      "|            datasetA|            datasetB|           distCol|\n",
      "+--------------------+--------------------+------------------+\n",
      "|[1, [Adventure, A...|[37830, [Action, ...|0.5714285714285714|\n",
      "|[1, [Adventure, A...|[54001, [Adventur...|0.7142857142857143|\n",
      "|[1, [Adventure, A...|[106489, [Adventu...|0.6666666666666667|\n",
      "|[2, [Adventure, C...|[3516, [Comedy, F...|               0.8|\n",
      "|[3, [Comedy, Roma...|[1746, [Comedy], ...|               0.5|\n",
      "+--------------------+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "genres_matches.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+------------------+\n",
      "|1st_movie|2nd_movie|           distCol|\n",
      "+---------+---------+------------------+\n",
      "|        1|    37830|0.5714285714285714|\n",
      "|        1|    54001|0.7142857142857143|\n",
      "|        1|   106489|0.6666666666666667|\n",
      "|        2|     3516|               0.8|\n",
      "|        3|     1746|               0.5|\n",
      "+---------+---------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Return movie-paired df with distance\n",
    "movies_dist = genres_matches.select (F.col('datasetA.movieId').alias('1st_movie'),\n",
    "                                    F.col('datasetB.movieId').alias('2nd_movie'),\n",
    "                                    F.col('distCol'))\n",
    "movies_dist.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------------------+----------+\n",
      "|1st_movie|2nd_movie|            distCol|similarity|\n",
      "+---------+---------+-------------------+----------+\n",
      "|        1|    37830| 0.5714285714285714|0.42857143|\n",
      "|        1|    54001| 0.7142857142857143| 0.2857143|\n",
      "|        1|   106489| 0.6666666666666667|0.33333334|\n",
      "|        2|     3516|                0.8|       0.2|\n",
      "|        3|     1746|                0.5|       0.5|\n",
      "|        3|     2431| 0.6666666666666667|0.33333334|\n",
      "|        3|     4347| 0.6666666666666667|0.33333334|\n",
      "|        3|     6619|                0.5|       0.5|\n",
      "|        3|    62439|                0.0|       1.0|\n",
      "|        3|    66509| 0.6666666666666667|0.33333334|\n",
      "|        3|    96616|                0.5|       0.5|\n",
      "|        3|   104076|               0.75|      0.25|\n",
      "|        4|     6415|0.33333333333333337| 0.6666667|\n",
      "|        4|     8614|0.33333333333333337| 0.6666667|\n",
      "|        4|    31049|               0.75|      0.25|\n",
      "|        4|    80584|                0.0|       1.0|\n",
      "|        4|   118814|0.33333333333333337| 0.6666667|\n",
      "|        4|   138546| 0.6666666666666667|0.33333334|\n",
      "|        5|      250|                0.5|       0.5|\n",
      "|        5|      437|                0.0|       1.0|\n",
      "+---------+---------+-------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate similarity from distance\n",
    "\n",
    "# Create function to calculate similarity\n",
    "def similarity(distance):\n",
    "    return 1- distance\n",
    "\n",
    "# define UDF\n",
    "udfsim = F.udf(similarity, T.FloatType())\n",
    "\n",
    "# Create similarity using UDF\n",
    "movies_dist = movies_dist.withColumn('similarity', udfsim(movies_dist.distCol))\n",
    "\n",
    "# Show the DataFrame\n",
    "movies_dist.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df with 1st movie title\n",
    "sim_with_title = movies_dist.join(movies, F.col('1st_movie') == F.col('movieId'))\\\n",
    "                            .select('1st_movie',F.col('title').alias('1st_movie_title'),'similarity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+---------+----------+\n",
      "|1st_movie| 1st_movie_title|2nd_movie|similarity|\n",
      "+---------+----------------+---------+----------+\n",
      "|        1|Toy Story (1995)|    37830|0.42857143|\n",
      "|        1|Toy Story (1995)|    54001| 0.2857143|\n",
      "+---------+----------------+---------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sim_with_title.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df with 1st and 2nd movie title\n",
    "sim_all_titles = sim_with_title.join(movies, F.col('2nd_movie')== F.col('movieId'))\\\n",
    "                               .select('1st_movie', '1st_movie_title',\\\n",
    "                                       '2nd_movie', F.col('title').alias('2nd_movie_title'),'similarity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+---------+--------------------+----------+\n",
      "|1st_movie| 1st_movie_title|2nd_movie|     2nd_movie_title|similarity|\n",
      "+---------+----------------+---------+--------------------+----------+\n",
      "|        1|Toy Story (1995)|    37830|Final Fantasy VII...|0.42857143|\n",
      "|        1|Toy Story (1995)|    54001|Harry Potter and ...| 0.2857143|\n",
      "+---------+----------------+---------+--------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sim_all_titles.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to return top 5 recommended movies\n",
    "def recommended_movies(movie_title):\n",
    "    return sim_all_titles.filter(col('1st_movie_title')== movie_title)\\\n",
    "                         .select('2nd_movie', '2nd_movie_title','similarity')\\\n",
    "                         .orderBy(\"similarity\", ascending = False).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+----------+\n",
      "|2nd_movie|     2nd_movie_title|similarity|\n",
      "+---------+--------------------+----------+\n",
      "|    87232|X-Men: First Clas...|       1.0|\n",
      "|    88140|Captain America: ...|       1.0|\n",
      "|     5264|Clockstoppers (2002)|       0.8|\n",
      "|     1127|   Abyss, The (1989)|       0.8|\n",
      "|    70336|G.I. Joe: The Ris...|       0.8|\n",
      "+---------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recommended_movies(\"Captain America: The First Avenger (2011)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Collaborative filtering engines\n",
    "   This engine recommends movies for each user based on their ratings.   \n",
    "   Using ALS algorithm, we will be able to find expected user's ratings on unseen movies based on their past behavior and from there, recommend high predicted rating movies to users.\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Inspect data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since ALS works better on sparsed data, we will inspect some figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating is 98.30% empty\n"
     ]
    }
   ],
   "source": [
    "# Variables to to calculate sparsity\n",
    "total_ratings = ratings.select('rating').count()\n",
    "num_users = ratings.select('userId').distinct().count()\n",
    "num_movies = ratings.select('movieId').distinct().count()\n",
    "\n",
    "# Calculate sparsity\n",
    "sparsity = (1.0 - float(total_ratings)/ (num_users * num_movies))*100\n",
    "print( 'Rating is','%.2f' %sparsity + '% empty')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Stats for ratings per movie:\n",
      "+----------+\n",
      "|min(count)|\n",
      "+----------+\n",
      "|         1|\n",
      "+----------+\n",
      "\n",
      "+----------+\n",
      "|max(count)|\n",
      "+----------+\n",
      "|       329|\n",
      "+----------+\n",
      "\n",
      "+------------------+\n",
      "|        avg(count)|\n",
      "+------------------+\n",
      "|10.369806663924312|\n",
      "+------------------+\n",
      "\n",
      " Stats for ratings per user:\n",
      "+----------+\n",
      "|min(count)|\n",
      "+----------+\n",
      "|        20|\n",
      "+----------+\n",
      "\n",
      "+----------+\n",
      "|max(count)|\n",
      "+----------+\n",
      "|      2698|\n",
      "+----------+\n",
      "\n",
      "+------------------+\n",
      "|        avg(count)|\n",
      "+------------------+\n",
      "|165.30491803278687|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect min, max and, avg of ratings per movie and user\n",
    "print(\" Stats for ratings per movie:\")\n",
    "ratings.groupBy('movieId').count().select(min('count')).show()\n",
    "ratings.groupBy('movieId').count().select(max('count')).show()\n",
    "ratings.groupBy('movieId').count().select(avg('count')).show()\n",
    "\n",
    "print(\" Stats for ratings per user:\")\n",
    "ratings.groupBy('userId').count().select(min('count')).show()\n",
    "ratings.groupBy('userId').count().select(max('count')).show()\n",
    "ratings.groupBy('userId').count().select(avg('count')).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test set using ratings df without timestamp\n",
    "ratings_df = ratings.select('userId', 'movieId', 'rating')\n",
    "\n",
    "(train,test) = ratings_df.randomSplit([0.8,0.2], seed =42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ALS model\n",
    "als = ALS (userCol ='userId',\n",
    "            itemCol = 'movieId',\n",
    "            ratingCol = 'rating',\n",
    "            nonnegative =True,\n",
    "            implicitPrefs = False,\n",
    "           coldStartStrategy=\"drop\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create param_grid to tune model\n",
    "param_grid = ParamGridBuilder() \\\n",
    "            .addGrid(als.rank,  [80,100,150] ) \\\n",
    "            .addGrid(als.maxIter, [50,100,150]) \\\n",
    "            .addGrid(als.regParam,  [.05,.1,.15,.2] ) \\\n",
    "            .build()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test models:  36\n"
     ]
    }
   ],
   "source": [
    "# create evaluator object\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", \n",
    "                                labelCol=\"rating\", \n",
    "                                predictionCol=\"prediction\") \n",
    "# Check number of test model\n",
    "print (\"Number of test models: \", len(param_grid))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossValidator_7620d1bdbd6e\n"
     ]
    }
   ],
   "source": [
    "# create CrossValidator object\n",
    "cv = CrossValidator(estimator=als, \n",
    "                    estimatorParamMaps=param_grid,\n",
    "                    evaluator=evaluator,\n",
    "                    numFolds=5)\n",
    "\n",
    "# Confirm cv was built\n",
    "print(cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALS.checkpointInterval = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-18149ca2ed90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Extract best model from the cv model above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbestModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#Fit to train set\n",
    "models = cv.fit(train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.ml.recommendation.ALSModel'>\n",
      "  Rank: 80\n",
      "  MaxIter: 50\n",
      "  RegParam: 0.15\n"
     ]
    }
   ],
   "source": [
    "# Return best model\n",
    "best_model = models.bestModel\n",
    "print(type(best_model))\n",
    "\n",
    "# # Return \"Rank\"\n",
    "print(\"  Rank:\", best_model._java_obj.parent().getRank())\n",
    "\n",
    "# Return \"MaxIter\"\n",
    "print(\"  MaxIter:\", best_model._java_obj.parent().getMaxIter())\n",
    "\n",
    "# Return \"RegParam\"\n",
    "print(\"  RegParam:\", best_model._java_obj.parent().getRegParam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8664535766468544\n"
     ]
    }
   ],
   "source": [
    "# View RMSE\n",
    "predictions = best_model.transform(test)\n",
    "RMSE = evaluator.evaluate(predictions)\n",
    "print(RMSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|     recommendations|\n",
      "+------+--------------------+\n",
      "|   471|[[96004, 4.681238...|\n",
      "|   463|[[33649, 4.896413...|\n",
      "|   496|[[5747, 4.2322197...|\n",
      "|   148|[[33649, 4.344435...|\n",
      "|   540|[[96004, 5.216998...|\n",
      "|   392|[[25771, 4.704468...|\n",
      "|   243|[[67618, 5.429157...|\n",
      "|    31|[[33649, 5.014798...|\n",
      "|   516|[[4429, 4.8194695...|\n",
      "|   580|[[6300, 4.6803193...|\n",
      "|   251|[[96004, 5.563831...|\n",
      "|   451|[[96004, 5.266256...|\n",
      "|    85|[[1140, 4.856921]...|\n",
      "|   137|[[96004, 4.808377...|\n",
      "|    65|[[96004, 4.787784...|\n",
      "|   458|[[67618, 5.209992...|\n",
      "|   481|[[51931, 3.946999...|\n",
      "|    53|[[96004, 6.692408...|\n",
      "|   255|[[1739, 3.8876514...|\n",
      "|   588|[[96004, 4.246173...|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate 5 best recommendations for all users\n",
    "recommendations = best_model.recommendForAllUsers(5)\n",
    "recommendations.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+---------+\n",
      "|userId|movieId|   rating|\n",
      "+------+-------+---------+\n",
      "|   471|  96004| 4.681238|\n",
      "|   471|   3379| 4.681238|\n",
      "|   471|  33649| 4.640755|\n",
      "|   471| 177593| 4.614352|\n",
      "|   471|  89904| 4.588294|\n",
      "|   463|  33649|4.8964133|\n",
      "|   463|  96004|4.8776793|\n",
      "|   463|   3379|4.8776793|\n",
      "|   463| 171495| 4.833774|\n",
      "|   463|  78836| 4.792316|\n",
      "+------+-------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Explode recommendations vector of each userId\n",
    "recommendations = recommendations.withColumn(\"recommendations_explode\", F.explode(\"recommendations\"))\\\n",
    "                                 .select('userId', col(\"recommendations_explode.movieId\"), col(\"recommendations_explode.rating\"))\n",
    "recommendations.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getmovierecom function to return recommended movies\n",
    "def getmovierecom(Id):\n",
    "    recom_df = recommendations.join(movies, on='movieId').filter(col('userId')==Id)\n",
    "    return recom_df.select('movieId', 'title','genres','rating').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+---------+\n",
      "|movieId|               title|              genres|   rating|\n",
      "+-------+--------------------+--------------------+---------+\n",
      "|  96004|Dragon Ball Z: Th...|Action|Adventure|...| 5.559495|\n",
      "|   3379| On the Beach (1959)|               Drama| 5.559495|\n",
      "| 132333|         Seve (2014)|   Documentary|Drama| 5.530093|\n",
      "|  33649|  Saving Face (2004)|Comedy|Drama|Romance| 5.445059|\n",
      "|   5915|Victory (a.k.a. E...|    Action|Drama|War|5.4239016|\n",
      "+-------+--------------------+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test function for userId 1\n",
    "getmovierecom(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movierated function to return movies watched and rated by users\n",
    "def movierated(Id):\n",
    "    ratedtitle = ratings.join(movies, on='movieId'). filter(col('userId')==Id)\n",
    "    return ratedtitle.select('movieId', 'title','genres','rating').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+------+\n",
      "|movieId|               title|              genres|rating|\n",
      "+-------+--------------------+--------------------+------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|   4.0|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|   4.0|\n",
      "|      6|         Heat (1995)|Action|Crime|Thri...|   4.0|\n",
      "|     47|Seven (a.k.a. Se7...|    Mystery|Thriller|   5.0|\n",
      "|     50|Usual Suspects, T...|Crime|Mystery|Thr...|   5.0|\n",
      "|     70|From Dusk Till Da...|Action|Comedy|Hor...|   3.0|\n",
      "|    101|Bottle Rocket (1996)|Adventure|Comedy|...|   5.0|\n",
      "|    110|   Braveheart (1995)|    Action|Drama|War|   4.0|\n",
      "|    151|      Rob Roy (1995)|Action|Drama|Roma...|   5.0|\n",
      "|    157|Canadian Bacon (1...|          Comedy|War|   5.0|\n",
      "|    163|    Desperado (1995)|Action|Romance|We...|   5.0|\n",
      "|    216|Billy Madison (1995)|              Comedy|   5.0|\n",
      "|    223|       Clerks (1994)|              Comedy|   3.0|\n",
      "|    231|Dumb & Dumber (Du...|    Adventure|Comedy|   5.0|\n",
      "|    235|      Ed Wood (1994)|        Comedy|Drama|   4.0|\n",
      "|    260|Star Wars: Episod...|Action|Adventure|...|   5.0|\n",
      "|    296| Pulp Fiction (1994)|Comedy|Crime|Dram...|   3.0|\n",
      "|    316|     Stargate (1994)|Action|Adventure|...|   3.0|\n",
      "|    333|    Tommy Boy (1995)|              Comedy|   5.0|\n",
      "|    349|Clear and Present...|Action|Crime|Dram...|   4.0|\n",
      "+-------+--------------------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# see movied rated by userId 1 to compare with recommended movies\n",
    "movierated(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save the ALS model\n",
    "best_model.write().overwrite().save('ALS')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
